{"cells":[{"cell_type":"markdown","id":"dafa483a-e084-4ba8-9236-5c0468364e0d","metadata":{},"source":["\n"," `telecom_demographics.csv` \n","\n","| Variable             | Description                                      |\n","|----------------------|--------------------------------------------------|\n","| `customer_id `         | Unique identifier for each customer.             |\n","| `telecom_partner `     | The telecom partner associated with the customer.|\n","| `gender `              | The gender of the customer.                      |\n","| `age `                 | The age of the customer.                         |\n","| `state`                | The Indian state in which the customer is located.|\n","| `city`                 | The city in which the customer is located.       |\n","| `pincode`              | The pincode of the customer's location.          |\n","| `registration_event` | When the customer registered with the telecom partner.|\n","| `num_dependents`      | The number of dependents (e.g., children) the customer has.|\n","| `estimated_salary`     | The customer's estimated salary.                 |\n","\n","`telecom_usage` \n","\n","| Variable   | Description                                                  |\n","|------------|--------------------------------------------------------------|\n","| `customer_id` | Unique identifier for each customer.                         |\n","| `calls_made` | The number of calls made by the customer.                    |\n","| `sms_sent`   | The number of SMS messages sent by the customer.             |\n","| `data_used`  | The amount of data used by the customer.                     |\n","| `churn`    | Binary variable indicating whether the customer has churned or not (1 = churned, 0 = not churned).|\n"]},{"cell_type":"code","execution_count":null,"id":"95efd3c7-a48a-49c2-9df6-36f078de3b38","metadata":{"chartConfig":{"bar":{"hasRoundedCorners":true,"stacked":false},"type":"bar","version":"v1"},"executionCancelledAt":null,"executionTime":15,"lastExecutedAt":1714929370512,"lastExecutedByKernel":"34f837e8-69e6-44b0-9b4f-fad60c59884e","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Import libraries and methods/functions\nimport pandas as pd\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder \nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import RidgeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import classification_report, confusion_matrix\n\n# Import required libraries and methods/functions\nimport pandas as pd\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder \n# OneHotEncoder is not needed if using pd.get_dummies()\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression \nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import classification_report, confusion_matrix\n","outputsMetadata":{"0":{"height":542,"type":"stream"},"1":{"height":211,"type":"dataFrame"}},"visualizeDataframe":false},"outputs":[],"source":["# Import libraries and methods/functions\n","import pandas as pd\n","from sklearn.preprocessing import StandardScaler, OneHotEncoder \n","from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import RidgeClassifier\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.metrics import classification_report, confusion_matrix\n","\n","# Import required libraries and methods/functions\n","import pandas as pd\n","from sklearn.preprocessing import StandardScaler, OneHotEncoder \n","# OneHotEncoder is not needed if using pd.get_dummies()\n","from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LogisticRegression \n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.metrics import classification_report, confusion_matrix\n"]},{"cell_type":"markdown","id":"5bda5f10-2c78-461f-a9f2-a0b2069157ec","metadata":{},"source":["## 1. Data Loading and Exploration \n","We start by loading and merging the two datasets into a dataframe. We calculate the rate of churn and identify the categorical values. "]},{"cell_type":"code","execution_count":null,"id":"80bd210d-1f34-4f5c-88a9-946126fabf4f","metadata":{"executionCancelledAt":null,"executionTime":39,"lastExecutedAt":1714929498922,"lastExecutedByKernel":"34f837e8-69e6-44b0-9b4f-fad60c59884e","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Load data\ntelco_demog = pd.read_csv('telecom_demographics.csv')\ntelco_usage = pd.read_csv('telecom_usage.csv')\n\n# Join data\nchurn_df = telco_demog.merge(telco_usage, on='customer_id')\n\n# Identify churn rate\nchurn_rate = churn_df['churn'].value_counts() / len(churn_df)\nprint(churn_rate)\n\n# Identify categorical variables\nprint(churn_df.info())\n","outputsMetadata":{"0":{"height":542,"type":"stream"},"1":{"height":211,"type":"dataFrame"}}},"outputs":[{"name":"stdout","output_type":"stream","text":["0    0.799538\n","1    0.200462\n","Name: churn, dtype: float64\n","<class 'pandas.core.frame.DataFrame'>\n","Int64Index: 6500 entries, 0 to 6499\n","Data columns (total 14 columns):\n"," #   Column              Non-Null Count  Dtype \n","---  ------              --------------  ----- \n"," 0   customer_id         6500 non-null   int64 \n"," 1   telecom_partner     6500 non-null   object\n"," 2   gender              6500 non-null   object\n"," 3   age                 6500 non-null   int64 \n"," 4   state               6500 non-null   object\n"," 5   city                6500 non-null   object\n"," 6   pincode             6500 non-null   int64 \n"," 7   registration_event  6500 non-null   object\n"," 8   num_dependents      6500 non-null   int64 \n"," 9   estimated_salary    6500 non-null   int64 \n"," 10  calls_made          6500 non-null   int64 \n"," 11  sms_sent            6500 non-null   int64 \n"," 12  data_used           6500 non-null   int64 \n"," 13  churn               6500 non-null   int64 \n","dtypes: int64(9), object(5)\n","memory usage: 761.7+ KB\n","None\n"]}],"source":["# Load data\n","telco_demog = pd.read_csv('telecom_demographics.csv')\n","telco_usage = pd.read_csv('telecom_usage.csv')\n","\n","# Join data\n","churn_df = telco_demog.merge(telco_usage, on='customer_id')\n","\n","# Identify churn rate\n","churn_rate = churn_df['churn'].value_counts() / len(churn_df)\n","print(churn_rate)\n","\n","# Identify categorical variables\n","print(churn_df.info())\n"]},{"cell_type":"markdown","id":"a5c43aee-ae7b-4595-a709-c39370b6ffd2","metadata":{},"source":["## 2. Feature Engineering \n","Then let's convert categorical variables to numeric, drop irrelevant features, standardize and transform relevant features, and define target column."]},{"cell_type":"code","execution_count":null,"id":"b1bc5706-6415-4328-bc7d-b47e715efaa5","metadata":{"executionCancelledAt":null,"executionTime":178,"lastExecutedAt":1714929370740,"lastExecutedByKernel":"34f837e8-69e6-44b0-9b4f-fad60c59884e","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# One Hot Encoding for categorical variables\nchurn_df = pd.get_dummies(churn_df, columns=['telecom_partner', 'gender', 'state', 'city', 'registration_event'])\n\n# Feature Scaling\nscaler = StandardScaler()\n\n# 'customer_id' is not a feature\nfeatures = churn_df.drop(['customer_id', 'churn'], axis=1)\nfeatures_scaled = scaler.fit_transform(features)\n\n# Target variable\ntarget = churn_df['churn']\n"},"outputs":[],"source":["# One Hot Encoding for categorical variables\n","churn_df = pd.get_dummies(churn_df, columns=['telecom_partner', 'gender', 'state', 'city', 'registration_event'])\n","\n","# Feature Scaling\n","scaler = StandardScaler()\n","\n","# 'customer_id' is not a feature\n","features = churn_df.drop(['customer_id', 'churn'], axis=1)\n","features_scaled = scaler.fit_transform(features)\n","\n","# Target variable\n","target = churn_df['churn']\n"]},{"cell_type":"markdown","id":"45421935-83ef-4269-b662-8ac6b2c6141d","metadata":{},"source":["## 3. Splitting the data\n","We split the processed data into training and testing sets giving names of X_train, X_test, y_train, and y_test using an 80-20 split, setting a random state of 42 for reproducibility."]},{"cell_type":"code","execution_count":null,"id":"d057bfae-c228-4667-9290-9ecbee43a82f","metadata":{"executionCancelledAt":null,"executionTime":51,"lastExecutedAt":1714929727637,"lastExecutedByKernel":"34f837e8-69e6-44b0-9b4f-fad60c59884e","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Splitting the dataset\nX_train, X_test, y_train, y_test = train_test_split(features_scaled, target, test_size=0.2, random_state=42)\n"},"outputs":[],"source":["# Splitting the dataset\n","X_train, X_test, y_train, y_test = train_test_split(features_scaled, target, test_size=0.2, random_state=42)\n"]},{"cell_type":"markdown","id":"c8cb402e-b46c-4304-9a89-e200bf46bf6d","metadata":{},"source":["## 4. Model fitting and predictions\n","We want to know whether Logistic Regression or Random Forest produce a higher score in predicting telecom churn. We instantiate and fit each model, set random seed of 42 and \n","store model predictions in logreg_pred and rf_pred.\n"]},{"cell_type":"code","execution_count":null,"id":"d18e378a-170d-4834-b0e0-e072c7064485","metadata":{"executionCancelledAt":null,"executionTime":2262,"lastExecutedAt":1714930867240,"lastExecutedByKernel":"34f837e8-69e6-44b0-9b4f-fad60c59884e","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Instantiate the Logistic Regression\nlogreg = LogisticRegression(random_state=42)\nlogreg.fit(X_train, y_train)\n\n# Logistic Regression predictions\nlogreg_pred = logreg.predict(X_test)\n","outputsMetadata":{"0":{"height":248,"type":"stream"}}},"outputs":[],"source":["# Instantiate the Logistic Regression\n","logreg = LogisticRegression(random_state=42)\n","logreg.fit(X_train, y_train)\n","\n","# Logistic Regression predictions\n","logreg_pred = logreg.predict(X_test)\n","\n","# Instantiate the Random Forest model\n","rf = RandomForestClassifier(random_state=42)\n","rf.fit(X_train, y_train)\n","\n","# Random Forest predictions\n","rf_pred = rf.predict(X_test)\n","\n"]},{"cell_type":"markdown","id":"f8252f57-86e8-4afc-a4d3-8d94021c1b2d","metadata":{},"source":["## 5. Model Assessment\n","We print confusion matrices and classification reports for each of the Logistic Regression and Random Forest models to assess model fit."]},{"cell_type":"code","execution_count":25,"id":"d5c24c02-636d-46de-aa39-664e5dc9145a","metadata":{"executionCancelledAt":null,"executionTime":null,"lastExecutedAt":null,"lastExecutedByKernel":null,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":null,"outputsMetadata":{"0":{"height":248,"type":"stream"}}},"outputs":[{"name":"stdout","output_type":"stream","text":["[[920 107]\n"," [245  28]]\n","              precision    recall  f1-score   support\n","\n","           0       0.79      0.90      0.84      1027\n","           1       0.21      0.10      0.14       273\n","\n","    accuracy                           0.73      1300\n","   macro avg       0.50      0.50      0.49      1300\n","weighted avg       0.67      0.73      0.69      1300\n","\n"]}],"source":["# Logistic Regression evaluation\n","print(confusion_matrix(y_test, logreg_pred))\n","print(classification_report(y_test, logreg_pred))"]},{"cell_type":"code","execution_count":26,"id":"6759131d-fc8b-48ff-a7e2-e98ba65ff5d0","metadata":{"executionCancelledAt":null,"executionTime":17,"lastExecutedAt":1714930910196,"lastExecutedByKernel":"34f837e8-69e6-44b0-9b4f-fad60c59884e","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Random Forest evaluation\nprint(confusion_matrix(y_test, rf_pred))\nprint(classification_report(y_test, rf_pred))","outputsMetadata":{"0":{"height":248,"type":"stream"}}},"outputs":[{"name":"stdout","output_type":"stream","text":["[[1026    1]\n"," [ 273    0]]\n","              precision    recall  f1-score   support\n","\n","           0       0.79      1.00      0.88      1027\n","           1       0.00      0.00      0.00       273\n","\n","    accuracy                           0.79      1300\n","   macro avg       0.39      0.50      0.44      1300\n","weighted avg       0.62      0.79      0.70      1300\n","\n"]}],"source":["# Random Forest evaluation\n","print(confusion_matrix(y_test, rf_pred))\n","print(classification_report(y_test, rf_pred))"]},{"cell_type":"markdown","id":"38ef86c0-2d1d-415d-9d8a-1cdbdd724bb1","metadata":{},"source":["## 6. Identify the model with higher accuracy\n","We look at the classification reports to see which accuracy score is closer to 1. We see that Logistic Regression has an accuracy score of 0.73 and Random Forest an accuracy score of 0.79\n"]},{"cell_type":"code","execution_count":27,"id":"d516e230-922d-4fcc-9c15-db4f1cd97f63","metadata":{"executionCancelledAt":null,"executionTime":11,"lastExecutedAt":1714930953587,"lastExecutedByKernel":"34f837e8-69e6-44b0-9b4f-fad60c59884e","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Which accuracy score is higher? Ridge or RandomForest\nhigher_accuracy = \"RandomForest\"\n"},"outputs":[],"source":["# Which accuracy score is higher? \n","higher_accuracy = \"RandomForest\"\n"]}],"metadata":{"colab":{"name":"Welcome to DataCamp Workspaces.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"}},"nbformat":4,"nbformat_minor":5}
